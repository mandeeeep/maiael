# Nepal National AI Policy Analysis - Complete Report

This document contains a comprehensive analysis of Nepal's National AI Policy, including case studies from Bangladesh, Rwanda, Sri Lanka, and Ghana, along with phased recommendations for implementation.

---

## Table of Contents

1. [Principle-Based AI Policy Compliance Framework](#1-principle-based-ai-policy-compliance-framework)
2. [Nepal National AI Policy Analysis](#2-nepal-national-ai-policy-analysis)
   - Ethics & Human Centricity
   - AI Adoption and Implementation
   - AI Use
   - Governance and Monitoring
   - Communication
   - Sustainable Growth
3. [Case Studies](#3-case-studies)
   - Bangladesh
   - Rwanda
   - Sri Lanka
   - Ghana
4. [Recommendations and Next Steps](#4-recommendations-and-next-steps)
   - Phase 1: Enablement with Proportionate Guardrails (0–6 months)
   - Phase 2: Scaling What Works (6–12 months)
   - Phase 3: Trust, Skills, and Long-Term Readiness (12–24 months)

---

## 1. Principle-Based AI Policy Compliance Framework

### Overview

This framework provides a structured approach to guide institutions and governments in defining, implementing, and assessing responsible AI policies. The framework is organized into 12 key principles across 6 compliance areas.

### Framework Definition

A proprietary DEC framework designed to guide institutions and governments in defining, implementing, and assessing responsible AI policies.

### Framework Structure

| Section | Title | Key Principles |
|---------|-------|----------------|
| 01 | Ethics and Human Centricity | Ethics and Human Centricity, Education/Literacy |
| 02 | AI Adoption and Implementation | Safety, Security and Robustness, Data Management and Quality, Innovation |
| 03 | AI Use | Transparency and Explainability, Fairness, Responsible AI use |
| 04 | Governance and Monitoring | Accountability and Governance, Incident Reporting, Contestability, and Redress |
| 05 | Communication | Transparency and Explainability, Incident Reporting, Contestability, and Redress |
| 06 | Sustainable Growth | Sustainable Development, Inclusive Growth |

**Source:** Digital Education Council (2025)

---

## 2. Nepal National AI Policy Analysis

### Ethics & Human Centricity

#### Definition

AI systems should be developed and deployed in a manner that aligns with human values, ensuring it serves as a tool for human empowerment rather than replacement.

#### Key Principles

- Ethics and Human Centricity
- Education/Literacy

#### Key Findings

**Strengths**

The policy demonstrates several notable strengths in its approach to ethics and human centricity. There is a clear and explicit commitment to human-centered and ethical AI that aligns with international norms and best practices. Ethics is positioned as a foundational value of the national AI vision, signaling its importance throughout all policy considerations. The policy shows a strong national commitment to AI literacy for the entire population, framed as an opportunity to "leapfrog existing gaps" in technological development. This literacy component serves a dual role, functioning both as an enabler of adoption and as a safeguard against misuse, supporting long-term responsible AI use across society.

**Gaps**

Despite these strengths, significant gaps remain in the practical implementation of ethical principles. The ethical principles articulated are currently expressed only at a "values level" with no translation into enforceable operational requirements that can be measured and verified. There are no mandatory ethical impact assessments required before AI system deployment, leaving a critical safeguard undefined. Additionally, there is no clear definition of when human oversight is required, recommended, or optional, creating uncertainty about accountability in AI-assisted decisions. Limited guidance exists on how ethical concerns should be identified, escalated, reviewed, or resolved in practice, leaving practitioners without clear pathways for addressing ethical challenges.

#### Key Opportunities

Build strong literacy foundation by formalizing ethical review and human-oversight requirements for high-impact AI systems. The goal is to ensure ethics moves "from aspiration to practice," transforming abstract principles into concrete operational requirements that can be implemented, monitored, and enforced.

---

### AI Adoption and Implementation

#### Definition

Integration of AI must be executed in a manner that ensures safety, security, and robust data management principles.

#### Key Principles

- Safety, Security, and Robustness
- Data Management and Quality
- Innovation

#### Key Findings

**Strengths**

The policy exhibits several strengths in its approach to AI adoption and implementation. There is a strong emphasis on national AI infrastructure, data systems, cybersecurity, and digital foundations, creating the necessary technical backbone for AI deployment. The policy demonstrates an explicit focus on enabling innovation, including regulatory sandboxes and experimentation environments that allow for controlled testing of new AI applications. The recognition that safety, security, and data quality are prerequisites for scaling AI responsibly shows a mature understanding of risk management. Finally, the clear intent to strengthen state capacity to deploy and manage AI systems indicates a commitment to building institutional capabilities.

**Gaps**

Several critical gaps remain in the implementation framework. There is no risk-based adoption lifecycle that enables distinction between pilots, controlled deployment, and full-scale implementation, leaving organizations without clear pathways for progressive deployment. While safety and security are recognized at a strategic level, these principles have not been translated into guidance or mechanisms that provide clarity and confidence for innovators and investors. No clear requirements exist for ongoing testing, validation, or monitoring once systems are deployed, creating potential blind spots in post-deployment risk management. Additionally, innovation and risk management are discussed in parallel rather than as integrated processes, suggesting a siloed approach to policy development.

#### Key Opportunities

Consider introducing a risk-gated AI adoption model (pilot → controlled deployment → scale) with defined safety, security, and data-quality conditions at each stage. This phased approach allows for progressive implementation while maintaining appropriate safeguards throughout the adoption lifecycle.

---

### AI Use

#### Definition

Use of AI and its processes should be transparent, with an emphasis on explainability and fairness throughout.

#### Key Principles

- Transparency and Explainability
- Fairness
- Responsible AI use

#### Key Findings

**Strengths**

The policy demonstrates meaningful strengths in its approach to AI use. The identification of a wide range of sectoral AI use cases, including education, health, agriculture, and public services, provides clear direction for targeted deployment. There is a strong emphasis on inclusion, access, and social benefit in AI deployment, ensuring that AI serves broader societal goals. The explicit acknowledgement of risks related to bias, misinformation, and misuse of AI systems indicates awareness of potential negative consequences and a foundation for risk mitigation.

**Gaps**

Significant gaps exist in the framework for acceptable AI use. There is no formal distinction between acceptable, high-risk, and prohibited AI uses, creating regulatory uncertainty about boundaries. Responsible AI use is encouraged but not defined in enforceable or testable terms, making compliance difficult to verify or measure. No explicit requirements exist for explainability or fairness in high-impact decisions affecting individuals, leaving vulnerable populations without clear protections. There is a risk of over-deployment in sensitive areas without adequate safeguards, potentially exposing citizens to untested or harmful AI applications.

#### Key Opportunities

Define clear boundaries for AI use, including risk tiers and minimum transparency and fairness requirements for high-impact applications. This will provide clarity for developers, deployers, and users while ensuring appropriate protections for individuals affected by AI systems.

---

### Governance and Monitoring

#### Definition

Clear accountability structures must govern AI, ensuring responsible oversight and channels for reporting and challenging AI decisions.

#### Key Principles

- Accountability and Governance
- Incident Reporting, Contestability, and Redress

#### Key Findings

**Strengths**

Governance and monitoring represent one of the strongest areas of the policy. The clearly defined institutional architecture involving the AI Regulation Council, National AI Centre, and AI Excellence Centres provides a comprehensive framework for oversight. There are explicit coordination, implementation, and review functions built into the governance design, ensuring that responsibilities are clearly assigned and activities are coordinated. The policy includes recognition of the need for ongoing monitoring and policy evolution, acknowledging that AI governance must remain adaptive to technological and societal changes.

**Gaps**

Despite these strengths, several gaps undermine the effectiveness of the governance framework. The accountability mechanisms with transparent oversight are described as "under-specified," leaving uncertainty about how oversight will actually function. There are no mandatory requirements for AI system inventories, logging, or traceability, making it difficult to track AI applications and assess their impact. No clear processes are defined for incident reporting, investigation, or remediation, leaving affected parties without recourse when harms occur. Mechanisms for contestability (challenging decisions) and redress for affected individuals are absent, denying citizens the ability to challenge AI-assisted decisions that affect their lives.

#### Key Opportunities

Operationalize governance by creating shared visibility, learning, and coordination mechanisms such as AI registries, feedback channels, and clear points of responsibility. This will help institutions and innovators scale AI use with confidence while leveraging the existing institutional setup.

---

### Communication

#### Definition

AI use and processes should be transparent, with clear channels for reporting issues, challenging outcomes, and ensuring fairness.

#### Key Principles

- Transparency and Explainability
- Incident Reporting, Contestability, and Redress

#### Key Findings

**Strengths**

The policy shows commitment to communication as a foundation for trust. There is commitment to public awareness, stakeholder engagement, and coordination across government, signaling openness about AI initiatives. Plans for national AI portals and communication mechanisms will support understanding of AI initiatives among the general public. The recognition that communication is important for trust-building demonstrates awareness of the social dimensions of AI adoption.

**Gaps**

The current approach to communication has significant limitations. Communication is framed primarily as information dissemination rather than as a right for affected individuals, missing the opportunity to empower citizens. There is no obligation to disclose AI use in public services or decision-making processes, leaving citizens unaware when AI systems affect their interactions with government. No clear channels exist for individuals to question, challenge, or appeal AI-assisted decisions, denying procedural fairness. Limited feedback loops exist to improve systems based on user experience or harm reports, preventing iterative learning and improvement.

#### Key Opportunities

Shift from awareness-based communication to rights-based transparency by requiring AI use disclosure and establishing clear channels for questions, challenges, and feedback. This transformation will empower citizens while building the trust necessary for widespread AI adoption.

---

### Sustainable Growth

#### Definition

AI should contribute to environmental, social, and economic sustainability, ensuring responsible use and equitable access and achieving inclusive growth.

#### Key Principles

- Sustainable Development
- Inclusive Growth

#### Key Findings

**Strengths**

The policy demonstrates strong alignment between AI strategy and national development goals. There is strong alignment between AI strategy and national development, inclusion, and economic growth objectives, ensuring that AI serves broader national priorities. Explicit attention to marginalized groups and equitable access to AI-enabled benefits demonstrates commitment to inclusive development. AI is positioned as a long-term contributor to social and economic resilience, recognizing the technology's potential for sustained positive impact.

**Gaps**

However, sustainability considerations remain largely aspirational rather than operational. There are no metrics to assess environmental or social impact of AI systems, making it impossible to measure progress or identify problems. Sustainability is not integrated into AI procurement or deployment decisions, missing opportunities to align purchasing power with sustainability goals. There is a risk that growth objectives are not matched with safeguards against negative externalities, potentially leading to unintended harms that undermine the benefits of AI adoption.

#### Key Opportunities

Embed sustainability into execution by introducing sustainability criteria for AI procurement and deployment, including environmental and inclusion considerations. This will operationalize sustainability principles and ensure they influence real-world decisions about AI systems.

---

## 3. Case Studies

### Case Study: Bangladesh

#### Key Policy Reference

Bangladesh's National Artificial Intelligence Policy (2024) Draft provides a high-level framework for AI strategy, governance, risk management, and capacity building, with emphasis on equitable growth, digital infrastructure, and human development.

#### Why Bangladesh is Relevant as a Case Study

Bangladesh's approach offers several lessons for AI policy development. The draft explicitly frames AI as an enabler for economic growth, public service efficiency, and social inclusion, linking technological adoption to national development priorities rather than treating AI as a standalone technology policy. The policy identifies education, digital literacy, and workforce reskilling as essential pillars, signaling that skills readiness is as important as regulatory readiness for successful AI adoption. The draft includes proposals for data governance structures, digital infrastructure, and interoperability standards, recognising that responsible AI depends on strong data foundations. The policy proposes governance mechanisms including steering committees and oversight frameworks that would help coordinate AI across ministries and sectors. Additionally, there is recognition of the need for collaboration with industry and academia supporting innovation, ensuring multiple stakeholders contribute to AI development.

#### Supporting Insights

While still a draft, Bangladesh's policy reflects a transition from aspirational digital strategy to concrete AI governance thinking, which is itself a useful benchmark for countries in early stages of AI policy development. The policy's explicit inclusion of workforce capacity building and digital inclusion objectives also provides an operationally grounded starting point for responsible AI adoption.

---

### Case Study: Rwanda

#### Key Policy Reference

Rwanda's National Artificial Intelligence Policy (2023) provides a national framework to harness AI for inclusive, sustainable growth, economic development, and innovation, with structured attention to ethics, skills, infrastructure, and governance.

#### Why Rwanda is Relevant as a Case Study

Rwanda's policy demonstrates several characteristics that make it instructive for other nations. The policy's vision and mission prioritize responsible and inclusive AI adoption, emphasising ethical use alongside practical development, showing that innovation and responsibility can be pursued together. The policy includes a focus on building AI literacy skills, recognising that human capital development is central to successful AI adoption at scale, not just in the technology sector but throughout the economy. The policy articulates the goal of building an open, secure, and trusted data ecosystem as a foundation for AI deployment, acknowledging that data quality and governance are prerequisites for effective AI systems. The policy was developed through multi-stakeholder engagement involving government, civil society, and the private sector, helping ensure inclusivity and balancing opportunity with risk awareness. Rwanda has embarked on ethical and human-rights capacity building, including training initiatives such as judiciary training on AI, data protection, and rule of law to strengthen awareness of risks such as bias, discrimination, and accountability in AI adoption.

#### Supporting Insights

The policy's overarching objectives explicitly include positioning Rwanda as a Responsible AI Champion in Africa, reflecting a blend of innovation, governance, and ethical orientation. This demonstrates how developing nations can leverage AI to achieve regional leadership while maintaining responsible practices.

---

### Case Study: Sri Lanka

#### Key Policy Reference

Sri Lanka's National AI Strategy (2024 Draft) outlines a framework designed to accelerate responsible AI adoption, bolster local capabilities, and align AI initiatives with national goals such as inclusive growth, public-sector transformation, and Sustainable Development Goal (SDG) outcomes.

#### Why Sri Lanka is Relevant as a Case Study

Sri Lanka's strategy offers several notable characteristics. The strategy is guided by principles like inclusivity, responsibility, trustworthiness, transparency, and human-centricity, embedding ethical intent directly into the policy framework from the outset. The strategy prioritizes "agile and adaptive governance," suggesting iterative frameworks and public engagement to keep policies relevant as the AI landscape evolves rapidly, acknowledging the pace of technological change. It emphasizes AI literacy and skills development as foundational elements, including coordinated investments in data skills, digital education, and workforce development to reduce knowledge gaps across the population. The strategy identifies specific sectors for practical and scalable AI integration, including public services, education, healthcare, and Small and Medium-sized Enterprises (SMEs), providing concrete deployment pathways.

#### Supporting Insights

Stakeholders at events like "Scale Up Sri Lanka 2025" have discussed plans for an AI legislative roadmap, public-sector transformation, and accessible adoption pathways for SMEs, indicating a focus on pragmatic implementation alongside strategic vision.

---

### Case Study: Ghana

#### Key Policy Reference

Ghana's National Artificial Intelligence Strategy (2023–2033) is a decade-long framework designed to harness AI for inclusive and sustainable socioeconomic development, emphasizing governance and inclusion.

#### Why Ghana is Relevant as a Case Study

Ghana's strategy demonstrates several characteristics that make it instructive. The strategy clearly articulates attention to AI risks, ethics, human capital development, and innovation governance, providing a comprehensive approach that addresses multiple dimensions of AI development. It prioritizes expanding AI education and training at all levels to build local capacity, recognizing that human capital development is essential for sustainable AI adoption. The framework integrates data governance and infrastructure development while explicitly calling for public-private partnerships and collaboration, acknowledging that successful AI implementation requires coordinated effort across multiple stakeholders. The drafting of a dedicated Responsible AI Office and an Emerging Technologies Bill is currently underway, indicating progress toward establishing ethical standards and regulatory oversight.

#### Supporting Insights

The strategy has produced concrete initiatives that demonstrate practical implementation. The "One Million Coders Program" serves as a talent pipeline, creating opportunities for skill development and workforce preparation. Ghana has established international partnerships, specifically citing collaboration with UNESCO, which provides access to global best practices and frameworks. The approach includes engagement with stakeholders across various sectors, indicating a pragmatic approach to building governance capacity and ensuring inclusion across different segments of society.

---

## 4. Recommendations and Next Steps

### Phase 1: Enablement with Proportionate Guardrails (0–6 months)

#### Objective

Signal national intent, mobilise the ecosystem, and create confidence for AI adoption and investment.

#### Key Action Points

**1. Establish a National AI Taskforce**

Create a high-level National AI Taskforce chaired at the ministerial level. Its mandate is to enable AI adoption, investment, and capacity-building across the economy. The taskforce should be "predominantly technocratic," drawing on expertise from various industries to ensure informed, evidence-based decision-making. The taskforce is positioned as a "time-bound enabling body" meant to eventually evolve into a permanent "Nepal AI Commission" with clear strategic targets as capacity matures.

**2. Provide Light-Touch National Guidance to Support Responsible AI Use**

Offer shared, non-binding national guidance to assist institutions and companies in deploying AI responsibly. Keep low-risk uses such as productivity tools, analytics, and research support "explicitly friction-light" to encourage experimentation and innovation. Encourage the early identification of higher-impact uses so that safeguards can be designed over time rather than imposed upfront, allowing for proportionate regulation based on actual risk.

**3. Build a National Picture of AI Activity**

Establish a lightweight mechanism to understand where AI is already being used or piloted across sectors including public sector, education, and private sector. Use this information to identify promising use cases, reduce duplication of efforts, and support the scale-up of successful initiatives. This mapping exercise will inform future policy decisions and resource allocation.

#### Summary

This phase supports ecosystem-wide capacity building and early adoption without imposing heavy regulatory overhead.

---

### Phase 2: Scaling What Works (6–12 months)

#### Objective

Actively support the scaling of successful AI pilots by building skills, coordination, and confidence across the ecosystem.

#### Main Recommendations

**1. Roll Out National AI Skills and Training Initiatives**

Launch coordinated initiatives to build AI capabilities throughout the talent pipeline, specifically aligning these efforts with the priority use cases identified in pilot programs. Support educational institutions in updating their curricula to include practical AI skills, applied use cases, and responsible AI practices. Align training efforts with current labor market needs to enhance youth employability and assist in workforce transition, ensuring that skills development translates into economic opportunity.

**2. Establish a One-Stop Shop to Enable Pilots to Scale**

Create a centralized coordination and support system to help successful AI pilots expand beyond initial implementation. Provide a clear interface for organizations to access government support and connect with investors, resources, and talent. Use this mechanism as a signal of government endorsement for AI initiatives that align with national priorities and demonstrate value, building confidence among stakeholders.

**3. Encourage Responsible Scaling Through Practical Guidance**

Provide practical guidance to help organizations consider the implications of scaling AI systems, particularly those that materially affect people. Focus on simple inquiries to define who is affected by the AI and what human checks or safeguards are in place, emphasizing an iterative learning process rather than rigid compliance requirements. This approach balances innovation with responsible deployment.

#### Summary

This phase focuses on unlocking scale by investing in people, coordination, and confidence.

---

### Phase 3: Trust, Skills, and Long-Term Readiness (12–24 months)

#### Objective

Sustain AI adoption by building trust, policy stability, and long-term ecosystem confidence.

#### Main Recommendations

**1. Strengthen Trust Through Clear, Human-Centred Transparency**

Promote clear communication when AI is used in decisions or services that directly impact individuals across various sectors. Frame transparency as a method for "trust-building" rather than just "technical disclosure," recognizing that effective communication requires understanding the human impact of AI systems on individuals and communities.

**2. Create a Stable, Investment-Friendly Policy Environment**

Transition the "National AI Taskforce" into a permanent "National AI Commission" to ensure continuity, coordination, and policy stability. Use this Commission and a "one-stop shop" approach to provide investors, startups, and institutions with a clear, predictable interface for interacting with the government, reducing uncertainty and encouraging long-term commitment to AI development in Nepal.

**3. Embed Sustainability, Inclusion, and AI Literacy as Long-Term Value Drivers**

Position sustainability, inclusion, and AI literacy as "economic enablers" that support workforce readiness, youth employability, and responsible AI adoption at scale. Align literacy initiatives with real-world use cases in education, SMEs, startups, and public services so that these skills directly improve the quality of adoption and deliver tangible benefits to citizens and the economy.

#### Summary

This phase anchors Nepal's AI strategy in trust, skills, and long-term value creation.

