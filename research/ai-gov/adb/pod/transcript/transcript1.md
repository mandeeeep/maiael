Speaker 1: AI system should be developed and deployed in a manner that aligns with **human values** really ensuring that it serves as a tool for **human empowerment** rather than replacement. We talked about already a number of times about **jobs** and the impact that the on **economy** and I'm particularly happy to hear how is really looking at this in a very practical term and so uh when we look at the policy we notice that this is really all aspect of the policy.

Specifically, we do see that there is a **clear and explicit commitment to human center and ethical AI** which is really aligned with international norms and this really important starting point way. Uh what is also important is how **ethics is positioned as a foundational value** and there is a very clear and strong commitment to AI which as we will see is really an enabler also found in a number of comparable countries.

This is also important because the **literacy shouldn't just be seen as an enabler but also as a safe target against misuse** really supporting long-term uh responsible AI use. What we see in terms of the **next steps in some of the gaps** and this is really a challenge that we see in many different countries of the world. Um the most important next steps is really **understanding how we can support institutions, people uh companies to understand practically on how to assess certain ethics principles**. Also, how can we define when **human oversight** is required?
Speaker 1: To be a **broker to innovation** and this is happening in a number of cases. Talking about regulation, therefore we need to talk about the very important topic of **governance and monitoring**. This is actually one of the strongest areas that we see at the moment of the policy. Uh we're very interested to see how there is a really clear definition of a starting point for a **national infrastructure architecture**. And so we saw very interestingly how the document defines that there will be a AI integration council, the national AI center and a number of AI excellent centers. Um very important also how the policy really presents an **explicit coordination and interpretation** between all these entities. In terms of the gaps we do see that next step could be identifying u processes for incident reporting, investigation and communication but also **How can we look at the very important topic of accountability?**. Especially when sometimes the current oversight systems are a bit unspecified.

Speaker 1: Once again is important and we really think in practical terms asking simple questions for businesses and people to comply. When it comes to pillar number four and it's a pillar very dear to us because we do see that very often there are in many countries very interesting and strong policies. However, when these policies laws also are not communicated well enough, there is a bit of overlap and of gap between the what could be achieved and what is actually achieved. So, we look at the **communication angle** in a very important with a very important emphasis here. AI user process should really be **transparent** with clear challenge also for reporting issues, challenging outcomes and ensuring fairness.

Speaker 1: We need to make sure that the the people of Nepal do not see these are just to documented jobs from the government but this is actually an **infrastructure which is active** with clear chances for people businesses investors entrepreneurs to engage and so right now the policy already presents a strong commitment to public awareness stakeholder engagement and coordination also we do we're very excited to see that there is already a plan for national communication mechanism to support these AI initiatives which is really an **enabler for growth** and positive collaboration with the with the industry and the people. Um in terms of gaps u government in terms of the obligation especially to disclose the use at the moment this is something where we see there needs to be more structuring around how it is presented but also how to can and structure effective and clear channels for individuals to question, challenge or appeal to ISO decisions in a number of contexts and also when I mention about the loops, this is one of the very important areas that the future iterations of and the next steps of the policies will need to focus on also very important to reflect on how AI policy also brings the consideration of **new rights** and the new collaboration and a new relationship that people will have to itself. 

Speaker 1: Last but not least, **sustainable growth**. At the moment, one of the key strength of the of the policy, it is the strong alignment between the **AI strategy and the national development, inclusion and economic growth objective**, which is really a fundamental starting point, but also we do commend the explicit attention to **marginalized group** and then predictable access to the enabled benefits which is really an important point in a in a developing country. U going forward may want to look at the metrics to environmental social impact of AI systems, but also how can it embed sustainability also in employment decisions and investment decision also making it very clear for investors and businesses.

Speaker 1: We wanted to start by also reflecting on what other countries are doing around the world and what Nepal can learn from some examples. Uh here we have a few slides of course we won't go through the details right now but we want to highlight the key things for you to know and also what these examples really show. **Bangladesh** is a very interesting point because of course it's is is really very very close to to Nepal. But also the fact that example with their national artificial intelligence policy rap document published last year shows how early stage policy can focus on **skills infrastructure and coordination also before regulation**. This is really important point as as we will also explain shortly on how an effective policy in a country like Nepal will need to look at how the regulation can be **proportionate to the reality of the country** but also very important look at how progress can proceed hand in hand with regulation and not overregulate before looking at how can we enable innovation to happen.

Speaker 1: **Rwanda** moving to Africa is also a very interesting example and we wanted really to reflect on the one example because they are starting to be very much successful in also positioning themselves as an **AI app** and this is relatively speaking small country in Africa but also demonstrated with the document already published in 2023 how also ethics skills and governance and move together especially in an capacity which is also of course the case of Rwanda moving back to to to Asia **Sri Lanka** is also a very interesting example they they published their document also in 2024 with their national strategy looking the framework to **accelerate responsible AI adoption** also support global capacity and align AI initiatives with national development goals. Um Sri Lanka is also an interesting example that highlights how adaptive governance and literate literacy first adoption can move together and you will see how this is a bit of a trend of merging AI literacy development with **adaptive cogence** which is really a key trend we see in similar countries. 

Speaker 1: And last but not least, we wanted also to mention **Ghana** today. Ghana is a particular interesting example of an under country with limited resources. But in this specific case, it shows actually how a **long-term planning skills pipeline** and signaling stability to investor can be very instrumental in certain countries. Actually the **signaling to the economy to the investor** is one of the key enabler to really make sure that AI policy don't stay just a beautiful document on hold but they really power the type of innovation inbound investments that the country would want. 